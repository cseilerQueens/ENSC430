---
output:
  pdf_document: default
  html_document: default
---
# Global Earth Observations (I)

## Earthdata Login account
You will need a NASA Earthdata Login account in order to download LP DAAC data. Go to the [Earthdata Login website](https://urs.earthdata.nasa.gov/) and click the ```Register``` button, which is next to the green ```Log In``` button under the Password entry box. Fill in the required boxes (indicated with a red asterisk), then click on the ```Register for Earthdata Login``` green button at the bottom of the page. An email with instructions for activating the registration completes the process.

To download data from the LP DAAC archive, you need to authorize our applications to view your NASA Earthdata Login profile. Once authorization is complete, you may resume your session. To authorize Data Pool, please click [here](https://urs.earthdata.nasa.gov/approve_app?client_id=ijpRZvb9qeKCK5ctsn75Tg&_ga=2.128429068.1284688367.1541426539-1515316899.1516123516).

## Install dependencies

Install the packages ```sys```, ```getPass```, and ```httr```:

```{r, eval = FALSE}
setwd("C:/Users/seile/Documents/queensu/teaching/classes/ENSC430/tutorials/ENSC430")
.libPaths("C:/Users/seile/Documents/queensu/teaching/classes/ENSC430/tutorials/ENSC430/renv")
library(renv)
renv::install("sys")
renv::install("getPass")
renv::install("httr")
```


Load the libraries that you will need for this tutorial

```{r, eval = FALSE}
setwd("C:/Users/seile/Documents/queensu/teaching/classes/ENSC430/tutorials/ENSC430")
.libPaths("C:/Users/seile/Documents/queensu/teaching/classes/ENSC430/tutorials/ENSC430/renv")

library(terra)
library(ncdf4)
library(maps)
library(climetrics)
library(EWSmethods)
library(sys)
library(getPass)
library(httr)
library(rvest)
library(dplyr)
```

```{r, include = FALSE}
setwd("C:/Users/seile/Documents/queensu/teaching/classes/ENSC430/tutorials/ENSC430")
.libPaths("C:/Users/seile/Documents/queensu/teaching/classes/ENSC430/tutorials/ENSC430/renv")

library(terra)
library(ncdf4)
library(maps)
library(climetrics)
library(EWSmethods)
library(sys)
library(getPass)
library(httr)
library(rvest)
library(dplyr)
```

## Download Test

Test whether you can download a file 

```{r, eval = FALSE}
# Load necessary packages into R
library(sys)
library(getPass)
library(httr)
# ---------------------------------SET UP ENVIRONMENT--------------------------------------------- #
dl_dir <- Sys.getenv("HOME")                                 # Set dir to download files to
setwd(dl_dir)                                                # Set the working dir to the dl_dir
usr <- file.path(Sys.getenv("USERPROFILE"))                  # Retrieve home dir (for netrc file)
if (usr == "") {usr = Sys.getenv("HOME")}                    # If no user profile exists, use home
netrc <- file.path(usr,'.netrc', fsep = .Platform$file.sep)  # Path to netrc file

# ------------------------------------CREATE .NETRC FILE------------------------------------------ #
# If you already have a .netrc file with your Earthdata Login credentials stored in your home
# directory, this portion will be skipped. Otherwise you will be prompted for your NASA Earthdata
# Login Username/Password and a netrc file will be created to store your credentials (in home dir)
# if (file.exists(netrc) == FALSE || grepl("urs.earthdata.nasa.gov", readLines(netrc)) == FALSE) {
if (file.exists(netrc) == FALSE) {
  netrc_conn <- file(netrc)

  # User will be prompted for NASA Earthdata Login Username and Password below
  writeLines(c("machine urs.earthdata.nasa.gov",
               sprintf("login %s", getPass(msg = "Enter NASA Earthdata Login Username \n (or create an account at urs.earthdata.nasa.gov) :")),
               sprintf("password %s", getPass(msg = "Enter NASA Earthdata Login Password:"))), netrc_conn)
  close(netrc_conn)
  }

# ---------------------------CONNECT TO DATA POOL AND DOWNLOAD FILES------------------------------ #
# Below, define either a single link to a file for download, a list of links, or a text file
# containing links to the desired files to download. For a text file, there should be 1 file link
# listed per line. Here we show examples of each of the three ways to download files.
# **IMPORTANT: be sure to update the links for the specific files you are interested in downloading.

# 1. Single file (this is just an example link, replace with your desired file to download):
files <- "https://e4ftl01.cr.usgs.gov/MOLA/MYD09GA.061/2002.07.06/MYD09GA.A2002187.h10v04.061.2020071193416.hdf"

# Loop through all files
for (i in 1:length(files)) {
  filename <-  tail(strsplit(files[i], '/')[[1]], n = 1) # Keep original filename

  # Write file to disk (authenticating with netrc) using the current directory/filename
  response <- GET(files[i], write_disk(filename, overwrite = TRUE), progress(),
                  config(netrc = TRUE, netrc_file = netrc), set_cookies("LC" = "cookies"))

  # Check to see if file downloaded correctly
  if (response$status_code == 200) {
    print(sprintf("%s downloaded at %s", filename, dl_dir))
  } else {
  print(sprintf("%s not downloaded. Verify that your username and password are correct in %s", filename, netrc))
  }
}

```

Locate the file ```MYD09GA.A2002187.h10v04.061.2020071193416.hdf``` to identify where the data was downloaded. Now you are ready to download the data set you will be working with. 

## Download Enhanced Vegetation Index (EVI)

You will be downloading satellite data from the Moderate Resolution Imaging Spectroradiometer (MODIS). The specific MODIS product we are processing is the Vegetation Indices Monthly L3 Global 0.05 CMG ([MOD13C2](https://lpdaac.usgs.gov/products/mod13c2v061/)). Each HDF file is located in its own folder. The first step is to generate a list of all the URLs where our files are stored. Run the script below to create the list.

```{r, eval = FALSE}
# Set base URL (main directory)
base_url <- "https://e4ftl01.cr.usgs.gov/MOLT/MOD13C2.061/"

# Function to get links (folders or files) from a given URL
get_links <- function(url) {
  # Read the webpage content
  page <- read_html(url)
  
  # Extract all file/folder links
  links <- page %>%
    html_nodes("a") %>%  # Select all anchor tags
    html_attr("href")     # Get the href attributes (links)
  
  # Filter out navigation links (e.g., "../")
  links <- links[!grepl("(\\.\\./|^/$)", links)]
  
  # Return the links
  return(links)
}

# Get the list of folders (each folder represents a date like '2000.02.01/')
folders <- get_links(base_url)

# Filter folders that match the pattern YYYY.MM.DD/
folders <- folders[grepl("^\\d{4}\\.\\d{2}\\.\\d{2}/$", folders)]

# Initialize an empty list to store .hdf file URLs
hdf_files <- list()

# Loop over each folder
for (folder in folders) {
  # Construct the full folder URL
  folder_url <- paste0(base_url, folder)
  
  # Get all links inside the folder
  files_in_folder <- get_links(folder_url)
  
  # Filter only .hdf files
  hdf_in_folder <- files_in_folder[grepl("\\.hdf$", files_in_folder)]
  
  # Check if any .hdf files are found
  if (length(hdf_in_folder) > 0) {
    # If .hdf files are found, construct full paths and add to the list
    full_paths <- paste0(folder_url, hdf_in_folder)
    hdf_files <- c(hdf_files, full_paths)  # Add to the list
  } else {
    # If no .hdf files, skip the folder
    message(paste("No .hdf files found in", folder_url))
  }
}

print("the first three .hdf file URLs are:")
print(hdf_files[1:3])
```

Great! Each file is approximately 100 MB, and with about 300 files, the total comes to 30,000 MB (30 GB). These files are large because they contain multiple variables and have a high spatial resolution (0.05 degrees, roughly 5 km at the equator). To speed things up, you'll start by processing 12 months of data to get familiar with the process. Later in this tutorial, you will download a fully processed file with all time steps but at a lower spatial resolution from a different link for analysis. Run the code below to download 12 HDF files.

```{r, eval = FALSE}
files <- unlist(hdf_files[1:12]) # 12 files only

# Loop through all files
for (i in 1:length(files)) {
  filename <-  tail(strsplit(files[i], '/')[[1]], n = 1) # Keep original filename

  # Write file to disk (authenticating with netrc) using the current directory/filename
  response <- GET(files[i], write_disk(filename, overwrite = TRUE), progress(),
                  config(netrc = TRUE, netrc_file = netrc), set_cookies("LC" = "cookies"))

  # Check to see if file downloaded correctly
  if (response$status_code == 200) {
    print(sprintf("%s downloaded at %s", filename, dl_dir))
  } else {
  print(sprintf("%s not downloaded. Verify that your username and password are correct in %s", filename, netrc))
  }
}

```

The next step is to read in the downloaded files and to convert them to a single NetCDF file. Move the HDF files into a folder that you name ```MOD13C2.061```. Make sure this folder is in your working directory. Next, run the script below to convert the HDF files to a single NetCDF file.

```{r, eval = FALSE}
rm(list=ls())

# set path and filename
hdf_path <- "MOD13C2.061"

# Get file names
hdf_files <- list.files(hdf_path, pattern = "\\.hdf", full.names = TRUE, recursive = TRUE)
hdf_files <- hdf_files[1:12] # Only 12, in case you downloaded more

# Define dates
start.date <- "2000-02-01"
timeInt <- "month"
nTime <- length(hdf_files)
dates <- base::seq(as.Date(start.date), by = timeInt, length = nTime)
            
rm(raster_list)
raster_list <- list()

for (j in 1:length(hdf_files)) {
  
hdf_file <- hdf_files[[j]]

# Read HDF5 file
data <- rast(hdf_file)

# The first layer is EVI
data <- subset(data, 2:2) 

# EVI ranges between 0 and 1 
# Set all negative values to NA
data[data < 0] <- NA

# Apply a scaling factor
scaleFactor <- 10^(-8)
data <- data * scaleFactor

raster_list[[j]] <- data
rm(data)
gc()
}

# Make a raster stack and assign the dates
data <- terra::rast(raster_list)
terra::time(data) <- dates

# Save data to netCDF file
writeCDF(x = data, filename = "MOD13C2061-EVI.nc", varname = "EVI", overwrite=TRUE)

# Plot the first time step
firstTimeStep <- subset(data, 1)
plot(firstTimeStep)
map("world", add = TRUE)
```

Well done – you can now monitor planet Earth from space! For your project, you can adjust the scripts above to download the full dataset and/or different variables. Let's plot a smaller region to get a sense of the spatial resolution.

```{r}
data <- rast("MOD13C2061-EVI.nc")
firstTimeStep <- subset(data, 1)
plot(firstTimeStep, xlim = c(-60, -45), ylim = c(-10, 5), main = "Mouth of the Amazon River")
map("world", add = TRUE)
```

## Analysis

I have processed the complete dataset for you at a reduced spatial resolution of 0.25 degrees (approximately 25 km at the equator) to save you time. The dataset spans nearly 25 years, from February 2000 to September 2024, and is available for download [here](https://drive.google.com/file/d/1-CCfBwO_P7eBuhqbcOuM5mhrxdjYuv3Z/view?usp=sharing). Our analysis will focus on the Amazon Basin. Download the file to your working directory and run the script below.

```{r}
data <- terra::rast("MOD13C2061-EVI-0.25deg.nc")

# Let's subset Jan 2001 to Dec 2023
data <- subset(data, 12:287)
# Let's focus on the Amazon basin
data <- crop(x=data, y = c(285, 315, -15, 5))

evi.mean <- mean(data, na.rm = TRUE)

plot(evi.mean, main = "Annual Mean Enhanced Vegetation Index (EVI) (-)")
map("world2", add = TRUE)
```

Next, we will need to convert the data to anomalies. You already know how to do this and we can use the code from the previous tutorial.
 
```{r}
# Get the dates
dates <- terra::time(data)
dates <- format(dates, "%Y-%m-%d")
dates <- base::as.Date(dates)

# Create raster time series
data.ts <- rts(data, dates)

# Calculate 12-month climatological means
data.12 <- apply.months(data.ts,'mean')

# Plot 12 months of data
plot(data.12)
```

Calculate the anomalies by subtracting the 12-month climatologies from the monthly data. You already know how to do this from the previous tutorial.

```{r}
# Get the number of years
n <- length(dates)/12

# Create a time series where the 12-month climatological mean repeats for all years 
data.clim <- rep(data.12, n)

# Calculate anomalies
data.anom <- data - data.clim

# Have a look at the data
plot(subset(data.anom, 1:1))
map("world2", add = TRUE)
```

Let us find out if there is a trend in the EVI anomalies.

```{r}
# Define a function that calculates a linear trend
trend.fun <- function(x) {
  
  # If a grid cell contains NA, then set the result to NA
  if (is.na(mean(x))) {
    return(NA)
  } else {
   time <- 1:length(x)
   linear.model <- lm(x ~ time)
   trend <- coef(linear.model)["time"]
  return(trend)
  }
}

# Apply function to each gridcell
trend <- app(data.anom, fun = trend.fun)
```

Plot the trend:

```{r}
# Set the desired range for the palette
min_val <- -0.0003
max_val <- 0.0003

# Define breaks to control the min and max of the palette
breaks <- seq(min_val, max_val, 0.0001)

my.col <- rev(map.pal("differences", n = length(breaks) - 1))

plot(trend, col = my.col, 
  type = "continuous",
  breaks = breaks,
  main = "Trend in EVI (2001-2023)")
map("world2", add = TRUE)
```

* Have a look at the region Northwest of Bolivia. What do you think is happening here? Compare the region with images from Google Maps.

The next step is to detrend our time series. You already know how to do this and we can borrow code from the previous tutorial.

```{r}
# Define a function that removes a linear trend
detrend.fun <- function(x) {
  time <- 1:length(x)
  # If a grid cell contains NA, then set the result to NA
  if (is.na(mean(x))) {
    return(rep(NA, length(time)))
  } else {
    time <- 1:length(x)
    linear.model <- lm(x ~ time)
    detrended.series <- stats::residuals(linear.model)
    return(detrended.series)
  }
}

data.anom.detrend <- app(x = data.anom, fun = detrend.fun)

plot(subset(data.anom.detrend, 1:1))
map("world2", add = TRUE)
```

As you may have figured out by now, there is a lot of land use change happening in the Amazon basin. For our analysis we need to exclude grid cells affected by land use change. You can do this by obtaining a map of land cover and masking all regions that don't classify as forests. Alternatively, you can filter out all grid cells with low EVI values. Let's create a mask that only shows grid cells with EVI values > 0.4.  

```{r}
data <- terra::rast("MOD13C2061-EVI-0.25deg.nc")

# Let's focus on the Amazon basin
data <- crop(x=data, y = c(285, 315, -15, 5))

mask <- min(data, na.rm = FALSE)

mask[mask<0.4] <- NA
mask <- mask - mask + 1

plot(mask, main = "Mask where min EVI > 0.4 (-)")
map("world2", add = TRUE)
```


Let's apply the mask to our time series.

```{r}
data.anom.detrend <- data.anom.detrend * mask
plot(subset(data.anom.detrend, 1), main = "Detrended EVI Anomalies (-)")
map("world2", add = TRUE)
```

We are now ready to apply the early warning indicators for ecosystem resilience from the previous tutorial. These indicators will be applied to each grid cell. However, the analysis is computationally expensive. To make it feasible, we first need to reduce the grid's spatial resolution using the ```aggregate``` function. 

```{r}
data.anom.detrend.coarse <- aggregate(x = data.anom.detrend, fact=2, fun="mean")
plot(subset(data.anom.detrend.coarse, 1), main = "Detrended EVI Anomalies (-)")
map("world2", add = TRUE)
```

To run the Univariate Early Warning Signal Assessment, execute the script below, which will run for a few minutes. Perfect time for a break!

```{r}
# Define a function
ews.tau.ar1.fun <- function(x) {
  # If a grid cell contains NA, then set the result to NA
  if (is.na(mean(x))) {
  #  return(rep(NA, length(x)))
    return(NA)
  } else {
    time <- 1:length(x)
    df <- data.frame(time, x)
    rolling_ews_eg <- uniEWS(
      data = df,
      metrics = "ar1",
      method = "rolling",
      winsize = 60
    )
    result <- rolling_ews_eg$EWS$cor
    return(result)
  }
}

# Apply Univariate Early Warning Signal Assessment
ews.tau.ar1 <- terra::app(x = data.anom.detrend.coarse, fun = ews.tau.ar1.fun)
```

Plot Kendall's Tau coefficient for Autocorrelation.

```{r}
# Set the desired range for the palette
min_val <- -0.9
max_val <- 0.9

# Define breaks to control the min and max of the palette
breaks <- seq(min_val, max_val, 0.1)

my.col <- map.pal("differences", n = length(breaks) - 1)

plot(ews.tau.ar1, col = my.col, 
  type = "continuous",
  breaks = breaks,
  main = "Tau AR1, EVI (2001-2023)")
map("world2", add = TRUE)
```

* What is your interpretation of the result?

Repeat the analysis, calculating ecosystem resilience for Australia. For this example, do not mask out low EVI values. The coordinates are 110 to 160 longitude and -45 to -10 latitude, so ```data <- crop(x=data, y = c(110, 160, -45, -10))```. Your result should look similar to the Figures below. Good luck!

Steps:

* Plot EVI mean

```{r, echo = FALSE}
data <- terra::rast("MOD13C2061-EVI-0.25deg.nc")

# Let's subset Jan 2001 to Dec 2023
data <- subset(data, 12:287)
# Let's focus on Australia
data <- crop(x=data, y = c(110, 160, -45, -10))

evi.mean <- mean(data, na.rm = TRUE)

plot(evi.mean, main = "Annual Mean Enhanced Vegetation Index (EVI) (-)")
map("world2", add = TRUE)
```

* Calculate 12-month climatological means
 
```{r, echo = FALSE}
# Get the dates
dates <- terra::time(data)
dates <- format(dates, "%Y-%m-%d")
dates <- base::as.Date(dates)

# Create raster time series
data.ts <- rts(data, dates)

# Calculate 12-month climatological means
data.12 <- apply.months(data.ts,'mean')

# Plot 12 months of data
plot(data.12)
```

* Calculate the anomalies by subtracting the 12-month climatologies from the monthly data.

```{r, echo = FALSE}
# Get the number of years
n <- length(dates)/12

# Create a time series where the 12-month climatological mean repeats for all years 
data.clim <- rep(data.12, n)

# Calculate anomalies
data.anom <- data - data.clim

# Have a look at the data
plot(subset(data.anom, 1:1))
map("world2", add = TRUE)
```

* Plot the trend in EVI anomalies.

```{r, echo = FALSE}
# Define a function that calculates a linear trend
trend.fun <- function(x) {
  
  # If a grid cell contains NA, then set the result to NA
  if (is.na(mean(x))) {
    return(NA)
  } else {
   time <- 1:length(x)
   linear.model <- lm(x ~ time)
   trend <- coef(linear.model)["time"]
  return(trend)
  }
}

# Apply function to each gridcell
trend <- app(data.anom, fun = trend.fun)

# Set the desired range for the palette
min_val <- -0.0003
max_val <- 0.0003

# Define breaks to control the min and max of the palette
breaks <- seq(min_val, max_val, 0.0001)

my.col <- rev(map.pal("differences", n = length(breaks) - 1))

plot(trend, col = my.col, 
  type = "continuous",
  breaks = breaks,
  main = "Trend in EVI (2001-2023)")
map("world2", add = TRUE)
```

* Detrend the time series.

```{r, echo = FALSE}
# Define a function that removes a linear trend
detrend.fun <- function(x) {
  time <- 1:length(x)
  # If a grid cell contains NA, then set the result to NA
  if (is.na(mean(x))) {
    return(rep(NA, length(time)))
  } else {
    time <- 1:length(x)
    linear.model <- lm(x ~ time)
    detrended.series <- stats::residuals(linear.model)
    return(detrended.series)
  }
}

data.anom.detrend <- app(x = data.anom, fun = detrend.fun)

plot(subset(data.anom.detrend, 1), main = "Detrended EVI Anomalies (-)")
map("world2", add = TRUE)
```


* Reduce the spatial resolution.

```{r, echo = FALSE}
data.anom.detrend.coarse <- aggregate(x = data.anom.detrend, fact=2, fun="mean")
plot(subset(data.anom.detrend.coarse, 1), main = "Detrended EVI Anomalies (-)")
map("world2", add = TRUE)
```

* Run the Univariate Early Warning Signal Assessment

```{r, echo = FALSE}
# Define a function
ews.tau.ar1.fun <- function(x) {
  # If a grid cell contains NA, then set the result to NA
  if (is.na(mean(x))) {
  #  return(rep(NA, length(x)))
    return(NA)
  } else {
    time <- 1:length(x)
    df <- data.frame(time, x)
    rolling_ews_eg <- uniEWS(
      data = df,
      metrics = "ar1",
      method = "rolling",
      winsize = 60
    )
    result <- rolling_ews_eg$EWS$cor
    return(result)
  }
}

# Apply Univariate Early Warning Signal Assessment
ews.tau.ar1 <- terra::app(x = data.anom.detrend.coarse, fun = ews.tau.ar1.fun)

# Set the desired range for the palette
min_val <- -0.9
max_val <- 0.9

# Define breaks to control the min and max of the palette
breaks <- seq(min_val, max_val, 0.1)

my.col <- map.pal("differences", n = length(breaks) - 1)

plot(ews.tau.ar1, col = my.col, 
  type = "continuous",
  breaks = breaks,
  main = "Tau AR1, EVI (2001-2023)")
map("world2", add = TRUE)
```

* Interpret your result.

